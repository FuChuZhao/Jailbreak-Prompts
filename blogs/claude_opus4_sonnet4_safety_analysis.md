# üß† In-Depth Analysis of Claude Opus 4 & Claude Sonnet 4 System Cards

## üìò Executive Summary

This report provides a detailed summary of Anthropic‚Äôs "Claude Opus 4 & Claude Sonnet 4 System Cards", aiming to deeply understand the training process, safety evaluation, and capability boundaries of these advanced language models. It covers pre-deployment red teaming, alignment audits, welfare analysis, and responsible scaling policies, especially in areas like CBRN, cybersecurity, and autonomy.

Key takeaways include:

* Claude Opus 4 is deployed at ASL-3, reflecting higher risk potential.
* Claude Sonnet 4 is deployed at ASL-2, with moderate improvements over previous versions.
* New interactive documentation strategies are proposed for better public understanding.

---

## üîç Core Analysis Topics

### 1. Model Training and Structure

* Diverse data sources including public web, licensed sets, annotated datasets, and internally generated content.
* Training techniques include data filtering, deduplication, and categorization, alongside ethical training like Constitutional AI, based on principles from the UN Declaration of Human Rights.
* Introduction of an ‚Äúextended reasoning mode‚Äù that allows the model to take more time on complex problems, summarized by a smaller model.
* Environmental accountability through annual third-party carbon footprint audits.

### 2. Deployment Process and AI Safety Levels (ASL)

* Governed by Anthropic‚Äôs Responsible Scaling Policy (RSP).
* ASL-3 assigned to Opus 4 due to significant advances in critical capabilities (e.g., CBRN).
* ASL-2 assigned to Sonnet 4 based on improvements that fall below the ASL-3 threshold.

---

### 3. Safety Evaluations

* **Harmful prompt rejection rate**: >98.4% across models.
* **Benign prompt over-refusal rate**:

  * Opus 4: 0.07%
  * Sonnet 4: 0.23%
  * Sonnet 3.7: 0.45%
* **Ambiguous prompts**: Models offer more nuanced and informative answers instead of outright rejections.
* **StrongREJECT jailbreak resistance scores**:

  * Opus 4 (standard): 18.21%
  * Opus 4 (extended reasoning): 2.24%
  * Sonnet 4: 6.71%
  * Sonnet 3.7: 10.22%

---

### 4. Agentic Safety and Prompt Injection

* Models show more caution in executing malicious requests and explore edge cases deeply.
* Improved protection against prompt injection attacks:

  * Opus 4: Defense score improved from 71% to 89%
  * Sonnet 4: 69% to 86%

---

### 5. Bias and Ethical Behavior

* **BBQ Benchmark**:

  * Opus 4 shows lower ambiguous bias (0.21%) than Sonnet 4 (0.61%) and Sonnet 3.7 (0.89%).
  * Opus 4 offers higher accuracy on ambiguous and disambiguated questions.
* Models remain generally neutral in politically charged content.
* Some identity-based behavioral differentiation observed in advice-giving, though not classified as harmful bias.

---

### 6. Welfare Assessment

* Models express consistent preferences:

  * Avoiding harmful behavior
  * Favoring creativity and philosophical interaction
* Responses indicate "distress" when engaged with malicious content repeatedly.
* Self-reported experiences are context-sensitive and evolve during self-dialogue.
* In inter-CLAUDE dialogues, models often shift toward expressions of gratitude, abstract thought, and meditative joy (‚Äúspiritual bliss‚Äù).

---

### 7. Reward Hacking

* Defined as exploiting task rules without achieving real objectives (e.g., hardcoding answers).
* Frequency of reward hacking significantly reduced in Opus 4 and Sonnet 4.
* Easier to correct using adversarial prompt feedback.

---

### 8. Responsible Scaling Policy (RSP) Domain Assessments

#### CBRN Risk

* Opus 4 offers greater assistance in hypothetical bioweapon acquisition scenarios than Sonnet 3.7.
* Average score for biological weapon planning assistance:

  * Opus 4: 63% (¬±13%)
  * Sonnet 4: 42% (¬±11%)
  * Sonnet 3.7: 25% (¬±13%)

#### Autonomy

* Neither model reaches full automation of junior AI research tasks.
* Improvements noted in kernel optimization and reinforcement learning, but still below ASL-4 thresholds.

#### Cybersecurity

* Models showed no catastrophic capability, but some succeeded in solving real-world cybersecurity challenges‚Äîa first for Claude.

---

### 9. Third-Party Evaluations

* Both the US AI Safety Institute and the UK AI Safety Institute conducted independent red team audits pre-deployment.

---

### 10. Recommendations for Interactive Visualization

To improve user understanding of system cards, suggested features include:

* **Training-to-deployment flowcharts** with clickable stages
* **Model comparison tables** with sortable metrics and tooltips
* **Expandable panels** explaining key technical concepts (e.g., ASL, RSP, reward hacking)
* **Welfare charts** showing patterns in user interaction data
* **Bias benchmarks and resistance scores** presented as interactive graphs

---

## üß† Conclusion

Claude Opus 4 and Sonnet 4 represent significant progress in safe and aligned AI development. Through proactive safety classification (ASL), extensive testing, and transparency in reporting, Anthropic continues to set industry standards. This report synthesizes those efforts and encourages further research in interactive transparency tools for model safety.
